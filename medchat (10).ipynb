{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11578770,"sourceType":"datasetVersion","datasetId":7259847}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install PyMuPDF","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:08.019121Z","iopub.execute_input":"2025-05-01T19:39:08.019990Z","iopub.status.idle":"2025-05-01T19:39:11.655939Z","shell.execute_reply.started":"2025-05-01T19:39:08.019959Z","shell.execute_reply":"2025-05-01T19:39:11.654803Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.5)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import fitz  # PyMuPDF\nimport re\nimport unicodedata\n\nimport re\nimport unicodedata\n\ndef clean_section_text(text):\n    lines = text.strip().splitlines()\n    cleaned = []\n\n    for line in lines:\n        line = line.strip()\n\n        # Supprimer le contenu entre parenthèses (ex : \"(see note)\")\n        line = re.sub(r\"\\([^)]*\\)\", \"\", line)\n\n        # Supprimer les lignes ne contenant qu’un chiffre\n        if re.fullmatch(r\"\\d{1,3}\", line):\n            continue\n\n        # Supprimer les mentions spécifiques inutiles\n        if \"International Medical Guide\" in line:\n            continue\n\n        # Supprimer une ligne si elle est une répétition directe de la précédente (même contenu)\n        if len(cleaned) == 1 and cleaned[0].lower() in line.lower():\n            cleaned.pop()\n            continue\n\n        # Supprimer les lignes commençant par \"See table\"\n        if line.lower().startswith(\"see table\"):\n            continue\n\n        # Supprimer les lignes comme \"Table 3.1 The characteristics...\" ou \"Table 12\"\n        if re.match(r\"^table\\s+\\d+(\\.\\d+)?(\\s|$)\", line.strip(), re.IGNORECASE):\n            continue\n\n        # Supprimer les lignes décrivant des types de douleur dans un tableau\n        if \"types of pain\" in line.lower() or \"nociceptive pain\" in line.lower():\n            continue\n\n\n        # Nettoyage des puces et symboles spéciaux\n        line = re.sub(r\"[■●◊:•▪❯]\", \"\", line)\n\n        # Supprimer les références à des chapitres ou figures\n        line = re.sub(r\"\\b(?:See\\s+)?Chapter\\s+\\d+\\b\", \"\", line, flags=re.IGNORECASE)\n        line = re.sub(r\"figure\\s?\\d+(?:\\.\\d+)?\", \"\", line, flags=re.IGNORECASE)\n\n        # Corriger les mots séparés par erreur (ex : \"s e c t i o n\" → \"section\")\n        line = re.sub(r\"\\b([A-Za-z])\\s+([A-Za-z])\\b\", r\"\\1\\2\", line)\n\n        # Corriger les ligatures typographiques\n        line = line.replace(\"ﬁ\", \"fi\").replace(\"ﬂ\", \"fl\")\n\n        # Supprimer les caractères de contrôle invisibles\n        line = ''.join(c for c in line if unicodedata.category(c)[0] != 'C')\n\n        # Ajouter la ligne nettoyée si elle est non vide\n        if line:\n            cleaned.append(line)\n\n    # Fusionner les lignes et séparer les phrases par des sauts de ligne après ponctuation\n    merged = ' '.join(cleaned)\n    return re.sub(r'([?.:])\\s+', r'\\1\\n', merged).strip()\n\n\ndef clean_title(title):\n    # Supprimer le contenu entre parenthèses dans les titres\n    title = re.sub(r\"\\([^)]*\\)\", \"\", title)\n    return re.sub(r\"[^\\w\\s\\-]\", \"\", title).strip().title()\n\ndef is_valid_section_title(text, size, bold, upper):\n    \"\"\"\n    Détermine si le texte est probablement un titre de section valide.\n    \"\"\"\n    if not text or len(text) < 2:\n        return False\n    if text.startswith('(') or text.endswith(')'):\n        return False\n    if text in [\"OR\", \"AND\"] and len(text) <= 3:\n        return False\n    if len(text.split()) == 1 and len(text) < 5 and not upper and not bold:\n        return False\n    return True\n\n# === DÉCOUPAGE EN CHAPITRES ET SECTIONS AVEC NETTOYAGE ===\ndef extract_chapters_and_sections(\n    pdf_path,\n    chapter_size=18,\n    section_size=14,\n    start_page=0,\n    end_page=None\n):\n    \"\"\"\n    Découpe le PDF en chapitres puis en sections :\n    - Chapitres détectés par taille de police >= chapter_size ou texte en MAJUSCULES\n    - Sections détectées par taille >= section_size ou style gras\n    Nettoie chaque chapitre avant de le découper en sections.\n    \"\"\"\n    doc = fitz.open(pdf_path)\n\n    # 1️⃣ Charger tout le texte pour positions globales\n    pages_text = []\n    page_offsets = []\n    for i, page in enumerate(doc):\n        if i < start_page or (end_page is not None and i > end_page):\n            continue\n        txt = page.get_text(\"text\")\n        page_offsets.append(len(\"\".join(pages_text)))\n        pages_text.append(txt)\n    full_text = \"\".join(pages_text)\n\n    # 2️⃣ Collecter tous les titres candidats (chapitre + section)\n    elems = []\n    for i, page in enumerate(doc):\n        if i < start_page or (end_page is not None and i > end_page):\n            continue\n        base = page_offsets[i - start_page]\n        d = page.get_text(\"dict\")\n        for block in d.get(\"blocks\", []):\n            for line in block.get(\"lines\", []):\n                if len(line[\"spans\"]) != 1:\n                    continue  # Ignorer les lignes avec plusieurs spans\n                span = line[\"spans\"][0]\n                txt = span.get(\"text\", \"\").strip()\n                if not txt:\n                    continue\n                sz = span.get(\"size\", 0)\n                flags = span.get(\"flags\", 0)\n                bold = bool(flags & 2)\n                upper = txt.isupper() and len(txt.split()) < 8\n\n                if not is_valid_section_title(txt, sz, bold, upper):\n                    continue\n\n                if sz >= section_size or bold or upper:\n                    pos = full_text.find(txt, base)\n                    elems.append({\"text\": txt, \"pos\": pos if pos >= 0 else base, \"page\": i, \"size\": sz, \"bold\": bold, \"upper\": upper})\n    elems.sort(key=lambda e: e[\"pos\"])\n\n    # 3️⃣ Séparer chapitres et sections\n    chapters = []\n    current = None\n    for e in elems:\n        if e[\"size\"] >= chapter_size or (e[\"upper\"] and e[\"size\"] >= section_size):\n            current = {\"title\": e[\"text\"], \"start\": e[\"pos\"], \"page\": e[\"page\"], \"sections\": []}\n            chapters.append(current)\n        else:\n            if current:\n                current[\"sections\"].append({\"title\": e[\"text\"], \"start\": e[\"pos\"], \"page\": e[\"page\"]})\n\n    # 4️⃣ Extraire le contenu du chapitre et ajouter la section \"Introduction\"\n    for i, chap in enumerate(chapters):\n        start = chap[\"start\"]\n        end = chapters[i+1][\"start\"] if i+1 < len(chapters) else len(full_text)\n\n        first_section_pos = chap[\"sections\"][0][\"start\"] if chap[\"sections\"] else end\n\n        intro_text = full_text[start:first_section_pos].strip()\n        intro_text = clean_section_text(intro_text)\n\n        sections = []\n        if intro_text and first_section_pos > start:\n            intro_section = {\n                \"title\": \"Introduction\",\n                \"start\": start,\n                \"page\": chap[\"page\"],\n                \"body\": intro_text\n            }\n            sections.append(intro_section)\n\n        for idx, sec in enumerate(chap[\"sections\"]):\n            sec_start = sec[\"start\"]\n            sec_end = chap[\"sections\"][idx+1][\"start\"] if idx+1 < len(chap[\"sections\"]) else end\n            sec_text = full_text[sec_start:sec_end].strip()\n            sections.append({\n                \"title\": clean_title(sec[\"title\"]),\n                \"page\": sec[\"page\"],\n                \"body\": clean_section_text(sec_text)\n            })\n\n        chap[\"sections\"] = sections\n\n    # 5️⃣ Formater les résultats finaux\n    results = []\n    for chap in chapters:\n        chap_dict = {\"title\": chap[\"title\"], \"page\": chap[\"page\"], \"sections\": chap[\"sections\"]}\n        results.append(chap_dict)\n\n    return results\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:11.657927Z","iopub.execute_input":"2025-05-01T19:39:11.658264Z","iopub.status.idle":"2025-05-01T19:39:11.686516Z","shell.execute_reply.started":"2025-05-01T19:39:11.658228Z","shell.execute_reply":"2025-05-01T19:39:11.685646Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    pdf = \"/kaggle/input/chatmed-set/datasetmedicalboot.pdf\"\n    structure = extract_chapters_and_sections(\n        pdf,\n        chapter_size=18,\n        section_size=14,\n        start_page=20,\n        end_page=428\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:11.687452Z","iopub.execute_input":"2025-05-01T19:39:11.687727Z","iopub.status.idle":"2025-05-01T19:39:14.778439Z","shell.execute_reply.started":"2025-05-01T19:39:11.687699Z","shell.execute_reply":"2025-05-01T19:39:14.777525Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"\n#     for chap in structure:\n#         print(f\"CHAPITRE: {chap['title']} (page {chap['page']})\")\n#         for sec in chap['sections']:\n#             print(f\"  - Section: {sec['title']} (page {sec['page']}), {len(sec['body'])} caractères\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:14.780675Z","iopub.execute_input":"2025-05-01T19:39:14.780962Z","iopub.status.idle":"2025-05-01T19:39:14.785328Z","shell.execute_reply.started":"2025-05-01T19:39:14.780940Z","shell.execute_reply":"2025-05-01T19:39:14.784493Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def remove_short_sections(chapters, min_length=100):\n    \"\"\"\n    Supprime :\n    - les sections de chaque chapitre ayant un corps de texte avec moins de `min_length` caractères.\n    - les chapitres ne contenant plus aucune section après le filtrage.\n    \"\"\"\n    cleaned_chapters = []\n    \n    for chap in chapters:\n        original_section_count = len(chap[\"sections\"])\n        chap[\"sections\"] = [sec for sec in chap[\"sections\"] if len(sec[\"body\"]) >= min_length]\n        removed = original_section_count - len(chap[\"sections\"])\n        \n        if removed:\n            print(f\"{removed} section(s) supprimée(s) dans le chapitre '{chap['title']}'\")\n        \n        if chap[\"sections\"]:\n            cleaned_chapters.append(chap)\n        else:\n            print(f\"Chapitre '{chap['title']}' supprimé car il ne contient aucune section valide.\")\n    \n    return cleaned_chapters\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:14.786423Z","iopub.execute_input":"2025-05-01T19:39:14.786671Z","iopub.status.idle":"2025-05-01T19:39:14.807705Z","shell.execute_reply.started":"2025-05-01T19:39:14.786651Z","shell.execute_reply":"2025-05-01T19:39:14.806690Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    pdf = \"/kaggle/input/chatmed-set/datasetmedicalboot.pdf\"\n    structure = extract_chapters_and_sections(\n        pdf,\n        chapter_size=18,\n        section_size=14,\n        start_page=20,\n        end_page=428\n    )\n\n    # 🔻 Nettoyage : supprimer les sections < 100 caractères\n    structure = remove_short_sections(structure, min_length=100)\n\n    # # 🔍 Affichage\n    # for chap in structure:\n    #     print(f\"CHAPITRE: {chap['title']} (page {chap['page']})\")\n    #     for sec in chap['sections']:\n    #         print(f\"  - Section: {sec['title']} (page {sec['page']}), {len(sec['body'])} caractères\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:14.808728Z","iopub.execute_input":"2025-05-01T19:39:14.809050Z","iopub.status.idle":"2025-05-01T19:39:17.835215Z","shell.execute_reply.started":"2025-05-01T19:39:14.809023Z","shell.execute_reply":"2025-05-01T19:39:17.834170Z"}},"outputs":[{"name":"stdout","text":"1 section(s) supprimée(s) dans le chapitre 'First aid'\nChapitre 'First aid' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'FIRST AID ON BOARD'\n8 section(s) supprimée(s) dans le chapitre 'A BASIC LIFE SUPPORT SEQUENCE'\n1 section(s) supprimée(s) dans le chapitre 'BLEEDING'\n2 section(s) supprimée(s) dans le chapitre 'ANATOMICAL NOTE'\n1 section(s) supprimée(s) dans le chapitre 'Eye injuries and diseases'\nChapitre 'Eye injuries and diseases' supprimé car il ne contient aucune section valide.\n5 section(s) supprimée(s) dans le chapitre 'EYE INJURIES'\n4 section(s) supprimée(s) dans le chapitre 'NONINFECTIOUS EYE DISEASES'\n4 section(s) supprimée(s) dans le chapitre 'INFECTIOUS EYE DISEASES'\n22 section(s) supprimée(s) dans le chapitre 'SPECIFIC INJURIES'\nChapitre 'Abdominal and chest injuries' supprimé car il ne contient aucune section valide.\nChapitre 'Abdominal and chest injuries' supprimé car il ne contient aucune section valide.\n2 section(s) supprimée(s) dans le chapitre 'ABDOMINAL INJURIES'\n2 section(s) supprimée(s) dans le chapitre 'CHEST INJURIES'\n1 section(s) supprimée(s) dans le chapitre 'Wounds'\nChapitre 'Wounds' supprimé car il ne contient aucune section valide.\n3 section(s) supprimée(s) dans le chapitre 'HOW TO CLOSE A WOUND'\n1 section(s) supprimée(s) dans le chapitre 'LOCAL ANAESTHESIA'\n1 section(s) supprimée(s) dans le chapitre 'SPECIAL WOUNDS'\n1 section(s) supprimée(s) dans le chapitre 'Burns, chemical splashes, smoke'\nChapitre 'Burns, chemical splashes, smoke' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'inhalation, and electrocution'\nChapitre 'inhalation, and electrocution' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'CLOTHING ON FIRE'\n1 section(s) supprimée(s) dans le chapitre 'HEAT BURNS AND SCALDS'\n1 section(s) supprimée(s) dans le chapitre 'ELECTRICAL BURNS AND ELECTROCUTION'\n1 section(s) supprimée(s) dans le chapitre 'Heat stroke and other'\nChapitre 'Heat stroke and other' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'heat disorders'\nChapitre 'heat disorders' supprimé car il ne contient aucune section valide.\n3 section(s) supprimée(s) dans le chapitre 'TO PREVENT HEAT STROKE'\n1 section(s) supprimée(s) dans le chapitre 'POISONING WITH INGESTED DRUGS'\nChapitre 'POISONING WITH INGESTED DRUGS' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'AND CHEMICALS'\n11 section(s) supprimée(s) dans le chapitre 'COMMON POISONING AGENTS'\n1 section(s) supprimée(s) dans le chapitre 'POISONING FROM EXPOSURE'\nChapitre 'POISONING FROM EXPOSURE' supprimé car il ne contient aucune section valide.\n5 section(s) supprimée(s) dans le chapitre 'TO COMMON GASES OR VAPOURS'\n7 section(s) supprimée(s) dans le chapitre 'BITES AND STINGS'\n1 section(s) supprimée(s) dans le chapitre 'Paralysis, strange behaviour,'\nChapitre 'Paralysis, strange behaviour,' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'unconsciousness'\nChapitre 'unconsciousness' supprimé car il ne contient aucune section valide.\n3 section(s) supprimée(s) dans le chapitre 'STROKE'\n1 section(s) supprimée(s) dans le chapitre 'HEADACHE'\n1 section(s) supprimée(s) dans le chapitre 'LOSS OF CONSCIOUSNESS'\n7 section(s) supprimée(s) dans le chapitre 'MENTAL ILLNESS'\n1 section(s) supprimée(s) dans le chapitre 'Chest pain and other disorders'\nChapitre 'Chest pain and other disorders' supprimé car il ne contient aucune section valide.\n3 section(s) supprimée(s) dans le chapitre 'ANGINA PECTORIS'\n1 section(s) supprimée(s) dans le chapitre 'Respiratory diseases'\nChapitre 'Respiratory diseases' supprimé car il ne contient aucune section valide.\n2 section(s) supprimée(s) dans le chapitre 'BRONCHITIS'\n1 section(s) supprimée(s) dans le chapitre 'BRONCHIECTASIS'\n1 section(s) supprimée(s) dans le chapitre 'COMMON COLD'\n2 section(s) supprimée(s) dans le chapitre 'PNEUMONIA'\n2 section(s) supprimée(s) dans le chapitre 'HAY FEVER'\n1 section(s) supprimée(s) dans le chapitre 'Gastrointestinal and liver diseases'\nChapitre 'Gastrointestinal and liver diseases' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'ABDOMINAL PAIN – GENERAL POINTS'\n2 section(s) supprimée(s) dans le chapitre 'SEVERE ABDOMINAL PAIN'\n10 section(s) supprimée(s) dans le chapitre 'DIARRHOEA'\n1 section(s) supprimée(s) dans le chapitre 'INDIGESTION AND PAIN RELATED TO'\nChapitre 'INDIGESTION AND PAIN RELATED TO' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'MEALS'\n1 section(s) supprimée(s) dans le chapitre 'HEAVY BLEEDING FROM THE'\nChapitre 'HEAVY BLEEDING FROM THE' supprimé car il ne contient aucune section valide.\n3 section(s) supprimée(s) dans le chapitre 'G ASTROINTESTINAL TRACT'\n2 section(s) supprimée(s) dans le chapitre 'LIVER AND BILIARY DISEASE'\n1 section(s) supprimée(s) dans le chapitre 'Kidney and other urinary disorders'\nChapitre 'Kidney and other urinary disorders' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'DISORDERS OF THE KIDNEY'\n3 section(s) supprimée(s) dans le chapitre 'OTHER URINARY DISORDERS'\n1 section(s) supprimée(s) dans le chapitre 'Pregnancy and childbirth'\nChapitre 'Pregnancy and childbirth' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'PREGNANCY'\n1 section(s) supprimée(s) dans le chapitre 'VAGINAL BLEEDING DURING PREGNANCY'\nChapitre 'VAGINAL BLEEDING DURING PREGNANCY' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'ECTOPIC PREGNANCY'\n10 section(s) supprimée(s) dans le chapitre 'CHILDBIRTH'\n1 section(s) supprimée(s) dans le chapitre 'URETHRITIS'\n1 section(s) supprimée(s) dans le chapitre 'ACUTE PAIN IN THE SCROTUM'\n2 section(s) supprimée(s) dans le chapitre 'LYMPH NODE SWELLING IN THE GROIN'\n2 section(s) supprimée(s) dans le chapitre 'VAGINAL DISCHARGE'\n4 section(s) supprimée(s) dans le chapitre 'BARBER’S RASH'\n2 section(s) supprimée(s) dans le chapitre 'CHAPS'\n4 section(s) supprimée(s) dans le chapitre 'DERMATITIS'\n3 section(s) supprimée(s) dans le chapitre 'FUNGAL SKIN INFECTIONS'\n2 section(s) supprimée(s) dans le chapitre 'BACTERIAL SKIN INFECTIONS'\n4 section(s) supprimée(s) dans le chapitre 'SKIN ABSCESS'\n3 section(s) supprimée(s) dans le chapitre 'CELLULITIS AND ERYSIPELAS'\n1 section(s) supprimée(s) dans le chapitre 'Bone, joint, and muscle'\nChapitre 'Bone, joint, and muscle' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'disorders'\nChapitre 'disorders' supprimé car il ne contient aucune section valide.\n2 section(s) supprimée(s) dans le chapitre 'SEPTIC ARTHRITIS'\n1 section(s) supprimée(s) dans le chapitre 'PROBLEMS IN SPECIFIC JOINTS'\n2 section(s) supprimée(s) dans le chapitre 'OPIOIDS, OPIATES, AND RELATED DRUGS'\n1 section(s) supprimée(s) dans le chapitre 'COMMON TERMS USED IN CONNECTION'\nChapitre 'COMMON TERMS USED IN CONNECTION' supprimé car il ne contient aucune section valide.\n2 section(s) supprimée(s) dans le chapitre 'WITH INFECTIONS'\n1 section(s) supprimée(s) dans le chapitre 'MANAGEMENT OF INFECTIOUS'\nChapitre 'MANAGEMENT OF INFECTIOUS' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'TREATING INFECTIOUS DISEASES'\n1 section(s) supprimée(s) dans le chapitre 'SOME COMMON OR IMPORTANT'\nChapitre 'SOME COMMON OR IMPORTANT' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'I NFECTIONS THAT COULD OCCUR ON'\nChapitre 'I NFECTIONS THAT COULD OCCUR ON' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'BOARD (presented here in alphabetical'\nChapitre 'BOARD (presented here in alphabetical' supprimé car il ne contient aucune section valide.\n18 section(s) supprimée(s) dans le chapitre 'order; for HIV/AIDS, see Chapter 19,'\n1 section(s) supprimée(s) dans le chapitre 'SOME COMMON DENTAL PROBLEMS'\n1 section(s) supprimée(s) dans le chapitre 'External assistance'\nChapitre 'External assistance' supprimé car il ne contient aucune section valide.\n4 section(s) supprimée(s) dans le chapitre 'MEDICAL ADVICE'\n2 section(s) supprimée(s) dans le chapitre 'EVACUATION BY HELICOPTER'\n1 section(s) supprimée(s) dans le chapitre 'SHIP-TO-SHIP TRANSFER OF DOCTOR OR'\nChapitre 'SHIP-TO-SHIP TRANSFER OF DOCTOR OR' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'REFERRAL INFORMATION TO ACCOMPANY'\nChapitre 'REFERRAL INFORMATION TO ACCOMPANY' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'Nursing care and medical'\nChapitre 'Nursing care and medical' supprimé car il ne contient aucune section valide.\n15 section(s) supprimée(s) dans le chapitre 'NURSING CARE'\n5 section(s) supprimée(s) dans le chapitre 'MEDICAL PROCEDURES'\n5 section(s) supprimée(s) dans le chapitre 'SURVIVING IN A SURVIVAL CRAFT'\n1 section(s) supprimée(s) dans le chapitre 'FOOD AND WATER FOR RESCUED'\nChapitre 'FOOD AND WATER FOR RESCUED' supprimé car il ne contient aucune section valide.\n2 section(s) supprimée(s) dans le chapitre 'FOOD HYGIENE'\n2 section(s) supprimée(s) dans le chapitre 'LIQUID TRANSPORT AND POTABLE WATER'\n4 section(s) supprimée(s) dans le chapitre 'COMBATING DISEASE VECTORS'\n1 section(s) supprimée(s) dans le chapitre 'Preventing disease and'\nChapitre 'Preventing disease and' supprimé car il ne contient aucune section valide.\n3 section(s) supprimée(s) dans le chapitre 'PREVENTING COMMUNICABLE DISEASES'\n1 section(s) supprimée(s) dans le chapitre 'PREVENTING OTHER DISEASES (See also'\n1 section(s) supprimée(s) dans le chapitre 'PREVENTING ILL-HEALTH FROM'\nChapitre 'PREVENTING ILL-HEALTH FROM' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'GENERAL PRINCIPLES OF PROMOTING'\nChapitre 'GENERAL PRINCIPLES OF PROMOTING' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'Anatomy and physiology'\nChapitre 'Anatomy and physiology' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'NOTE ON ANATOMICAL TERMS AND'\nChapitre 'NOTE ON ANATOMICAL TERMS AND' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'INTERNATIONAL HEALTH REGULATIONS'\nChapitre 'INTERNATIONAL HEALTH REGULATIONS' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'PART I – DEFINITIONS, PURPOSE AND SCOPE,'\nChapitre 'PART I – DEFINITIONS, PURPOSE AND SCOPE,' supprimé car il ne contient aucune section valide.\n1 section(s) supprimée(s) dans le chapitre 'PRINCIPLES AND RESPONSIBLE AUTHORITIES'\n1 section(s) supprimée(s) dans le chapitre 'PART IV – POINTS OF ENTRY'\n4 section(s) supprimée(s) dans le chapitre 'PART V – PUBLIC HEALTH MEASURES'\n2 section(s) supprimée(s) dans le chapitre 'PART VI – HEALTH DOCUMENTS'\n4 section(s) supprimée(s) dans le chapitre 'PART VII – CHARGES'\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"def afficher_sections_chapitre(chapters, chapitre_titre, nb_exemples=2, extrait_longueur=200):\n    \"\"\"\n    Affiche les premières sections d’un chapitre spécifique pour vérification.\n    \"\"\"\n    for chap in chapters:\n        if chap['title'].strip().lower() == chapitre_titre.strip().lower():\n            print(f\"\\n📘 CHAPITRE : {chap['title']} (page {chap['page']})\")\n            print(f\"Nombre de sections : {len(chap['sections'])}\")\n            print(\"-\" * 60)\n\n            for i, sec in enumerate(chap['sections'][:nb_exemples]):\n                print(f\"🔹 Section: {sec['title']} (page {sec['page']})\")\n                print(f\"Longueur: {len(sec['body'])} caractères\")\n                extrait = sec['body'][:extrait_longueur].strip().replace('\\n', ' ')\n                print(f\"Extrait: {extrait}...\")\n                print(\"-\" * 40)\n            return\n    \n    print(f\"Aucun chapitre trouvé avec le titre '{chapitre_titre}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:17.836442Z","iopub.execute_input":"2025-05-01T19:39:17.836709Z","iopub.status.idle":"2025-05-01T19:39:17.844646Z","shell.execute_reply.started":"2025-05-01T19:39:17.836689Z","shell.execute_reply":"2025-05-01T19:39:17.843328Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"afficher_sections_chapitre(structure, \"Pain management\", nb_exemples=3, extrait_longueur=700)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:17.845637Z","iopub.execute_input":"2025-05-01T19:39:17.846035Z","iopub.status.idle":"2025-05-01T19:39:17.871011Z","shell.execute_reply.started":"2025-05-01T19:39:17.846007Z","shell.execute_reply":"2025-05-01T19:39:17.869902Z"}},"outputs":[{"name":"stdout","text":"\n📘 CHAPITRE : Pain management (page 37)\nNombre de sections : 10\n------------------------------------------------------------\n🔹 Section: Introduction (page 37)\nLongueur: 1261 caractères\nExtrait: Pain management Pain is the result of the way in which the brain – and consequently the mind or consciousness  – interprets information about a sensation that the body is  experiencing. The brain receives the information in the form of signals that travel via nerve pathways to the brain. The sensation itself may originate in a tissue such as the skin or a bone, or in an internal organ, or even somewhere along the nerve pain pathways. How the brain receives or reacts to these signals to produce the perception of “pain” can be affected by many factors; for example stress or anxiety can make the mind more sensitive to pain, which is then experi- enced more intensely; inflammation of nerve pathw...\n----------------------------------------\n🔹 Section: Note On Assessing The Severity Of Pain (page 37)\nLongueur: 1407 caractères\nExtrait: Note on assessing the severity of pain Although there are cultural and individual differences in the way people react to pain, these  differences should not be taken into account when assessing pain severity the pain that needs to be managed is the pain that the patient complains of. A patient may have pain in more than one place, especially after an injury, and should be questioned about each pain separately a diagram of the body with each painful place marked on it can help to keep track of different pains in an ill or injured patient. A patient who answers a question about the severity of pain should be asked to specify whether the answer refers to the pain being experienced at that momen...\n----------------------------------------\n🔹 Section: What To Do  In General (page 38)\nLongueur: 3783 caractères\nExtrait: What to do – in general Develop a strategy that takes into account the patient’s needs and that may well go beyond the administration of analgesics to include alternative or additional options, such as application of local heat, which can reduce the severity of pain associated with inflammation; application of icepacks to a painful injury within the first 48 hours of its occurrence apply icepacks for 10 minutes every two hours (but NEVER directly on the skin) then firmly bandage and have the patient elevate the injured part. Neuropathic pain Arising from  skin  lining of mouth  anus  urethra  bones  joints  muscles  ligaments  linings, such as pleura and peritoneum  solid or hollow internal...\n----------------------------------------\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"for chap in structure:\n    for section in chap[\"sections\"]:\n        word_count = len(section[\"body\"].split())\n        if word_count > 1000:\n            print(\"=\" * 80)\n            print(f\"📘 Chapitre: {chap['title']}\")\n            print(f\"📄 Section: {section['title']} (Page {section['page']})\")\n            print(f\"📝 Nombre de mots: {word_count}\")\n            print(\"-\" * 80)\n            print(section[\"body\"][:1000] + \"...\")\n            print(\"=\" * 80 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:17.871688Z","iopub.execute_input":"2025-05-01T19:39:17.871986Z","iopub.status.idle":"2025-05-01T19:39:17.903193Z","shell.execute_reply.started":"2025-05-01T19:39:17.871963Z","shell.execute_reply":"2025-05-01T19:39:17.902249Z"}},"outputs":[{"name":"stdout","text":"================================================================================\n📘 Chapitre: THE PHYSICAL EXAMINATION\n📄 Section: Introduction (Page 129)\n📝 Nombre de mots: 1496\n--------------------------------------------------------------------------------\nTHE PHYSICAL EXAMINATION Unlike the fi rst stage of the basic medical examination, which focuses on subjective s ymptoms experienced and described by the patient, the physical examination looks for objective signs of abnormal functioning of the body.\nAgain, a systematic head-to-toe approach should be adopted .\nOrgan or system Ask the patient about past or present occurrences of Head  wounds , headache; Eyes  blurred vision, double vision, pain, yellow colour of the sclera , pain or discomfort on looking at a light source; Ears  loss of hearing, dizziness, pain, or drainage of fl uid; Nose  bleeding, runny, or stuﬀ y; Mouth and throat  sores, pain, diﬃ  culty swallowing; Neck  stiﬀ ness, enlarged lymph glands, pain; Respiratory system  coughing, sputum production, coughing up of blood, chest pain when breathing, shortness of breath; Cardiovascular system  chest pain, swelling of one or both legs, shortness of breath on exercising, breathlessness when sleeping fl at in bed, strong or rap...\n================================================================================\n\n================================================================================\n📘 Chapitre: NURSING CARE\n📄 Section: F (Page 324)\n📝 Nombre de mots: 1188\n--------------------------------------------------------------------------------\n°F °C Usually fatal Dangerous fever High fever Moderate fever Healthy  oral temperature Subnormal temperature Nursing care and medical procedures there are the same number of beats in every 15-second period and whether each beat has about the same force.\nIf the pulse beat is irregular, count the pulse at the wrist and also listen over the heart for a full minute in each case; note the rates may appear to be different between the wrist and the heart that is because you are able to hear weak heart beats but you may not be able to feel a weak pulse at the wrist.\nª  How to take the respiratory  rate To determine the respiratory rate, namely, the number of times per minute that the patient breathes in watch the patient and count the inspirations for a full minute but do so unobtrusively  if the patient is aware of what you are doing, the respiratory rate is likely to be irregular; note that the respiratory rate is a good indicator of the severity of many chest illnesses and chest injuries i...\n================================================================================\n\n================================================================================\n📘 Chapitre: PRINCIPLES AND RESPONSIBLE AUTHORITIES\n📄 Section: Article 1 Definitions (Page 413)\n📝 Nombre de mots: 1764\n--------------------------------------------------------------------------------\nARTICLE 1 DEFINITIONS 1.\nFor the purposes of the International Health Regulations (hereinafter the “IHR” or “Regulations”) “affected” means persons, baggage, cargo, containers, conveyances, goods, postal parcels or human remains that are infected or contaminated, or carry sources of infection or contamination, so as to constitute a public health risk; “affected area” means a geographical location specifi cally for which health measures have been recommended by WHO under these Regulations; “aircraft” means an aircraft making an international voyage; “airport” means any airport where international fl ights arrive or depart; “arrival” of a conveyance means in the case of a seagoing vessel, arrival or anchoring in the defi ned area of a port;  in the case of an aircraft, arrival at an airport; in the case of an inland navigation vessel on an international voyage, arrival at a point of entry;  in the case of a train or road vehicle, arrival at a point of entry; “baggage” means the personal ...\n================================================================================\n\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import json\n\nwith open(\"structure.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(structure, f, indent=2, ensure_ascii=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:17.905916Z","iopub.execute_input":"2025-05-01T19:39:17.906223Z","iopub.status.idle":"2025-05-01T19:39:17.946580Z","shell.execute_reply.started":"2025-05-01T19:39:17.906201Z","shell.execute_reply":"2025-05-01T19:39:17.945151Z"}},"outputs":[],"execution_count":46},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"# aproche 1","metadata":{}},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Aplatir les chapitres et sous-sections extraites en une liste de documents\nflat_subsections = []\nfor chapter in structure:\n    for section in chapter['sections']:\n        flat_subsections.append({\n            \"section\": chapter['title'],\n            \"subheader\": section['title'],\n            \"text\": section['body']\n        })\n\n# 1) Aplatir tes sous-sections en une liste de documents\ndocs = [f\"{item['subheader']}. {item['text']}\" for item in flat_subsections]\n\n# 2) Construire et entraîner le TF–IDF\nvectorizer = TfidfVectorizer(\n    lowercase=True,\n    stop_words='english',    # ou 'english' selon la langue de ton contenu\n    ngram_range=(1,2),       # unigrams + bigrams\n    min_df=2,                # ignorer les termes qui apparaissent < 2 docs\n)\ntfidf_matrix = vectorizer.fit_transform(docs)  # shape = (n_docs, n_features)\n\n# 3) Fonction de récupération top-k par similarité cosinus\ndef retrieve_tfidf_for_test(question, k=3):\n    # Vectoriser la question\n    q_vec = vectorizer.transform([question])\n    # Calculer les similarités\n    sims = cosine_similarity(q_vec, tfidf_matrix)[0]\n    # Récupérer les indices des k meilleurs scores\n    topk_idx = np.argsort(sims)[-k:][::-1]\n    results = []\n    for idx in topk_idx:\n        results.append({\n            \"section\": flat_subsections[idx][\"section\"],\n            \"subheader\": flat_subsections[idx][\"subheader\"],\n            \"text\": flat_subsections[idx][\"text\"],\n            \"score\": float(sims[idx])\n        })\n    return results\n\n# 4) Test rapide\nquestion =\" how applicate Mouth-To-Nose Rescue Breathing?\"\ntop3 = retrieve_tfidf_for_test(question, k=3)\nfor r in top3:\n    print(f\"→ {r['section']} / {r['subheader']} (score={r['score']:.3f})\")\n    print(r['text'][:200].replace('\\n',' ') + \"...\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:17.947698Z","iopub.execute_input":"2025-05-01T19:39:17.948032Z","iopub.status.idle":"2025-05-01T19:39:18.227852Z","shell.execute_reply.started":"2025-05-01T19:39:17.948003Z","shell.execute_reply":"2025-05-01T19:39:18.226847Z"}},"outputs":[{"name":"stdout","text":"→ A BASIC LIFE SUPPORT SEQUENCE / Mouth-To-Nose Rescue Breathing (score=0.384)\nthe patient’s mouth cannot be opened; a tight seal cannot be obtained around the patient’s lips; an obstruction cannot be removed from the patient’s mouth; the patient has been rescued from water and ...\n\n→ A BASIC LIFE SUPPORT SEQUENCE / Mouth-To-Mouth Rescue Breathing (score=0.371)\nMOUTH-TO-MOUTH RESCUE BREATHING With one hand under the patient’s neck, keep the patient’s head tilted as far back as it will go – unless you suspect spinal injury, in which case use minimal tilt. Pla...\n\n→ A BASIC LIFE SUPPORT SEQUENCE / Using A Bag And Mask Resuscitator (score=0.347)\nUSING A BAG AND MASK RESUSCITATOR A bag and mask resuscitator can be used for rescue breathing to replace mouth- to-mouth or mouth-to-nose breathing. The advantages of a bag and mask resuscitator are ...\n\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"question=\" how applicate Mouth-To-Nose Rescue Breathing?\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:18.228881Z","iopub.execute_input":"2025-05-01T19:39:18.229374Z","iopub.status.idle":"2025-05-01T19:39:18.234772Z","shell.execute_reply.started":"2025-05-01T19:39:18.229251Z","shell.execute_reply":"2025-05-01T19:39:18.233489Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel_name = \"google/flan-t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# Fusionner les 3 meilleurs contextes pour donner à T5\ncombined_context = \" \".join([r[\"text\"] for r in top3])\n\n# Préparer le prompt pour le modèle\ninput_text = f\"question: {question} context: {combined_context} answer:\"\ninputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n\n# Générer la réponse\noutput = model.generate(**inputs, max_length=300)\nanswer = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(\"🧠 Réponse générée:\", answer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:18.236417Z","iopub.execute_input":"2025-05-01T19:39:18.237529Z","iopub.status.idle":"2025-05-01T19:39:20.668682Z","shell.execute_reply.started":"2025-05-01T19:39:18.237492Z","shell.execute_reply":"2025-05-01T19:39:20.667783Z"}},"outputs":[{"name":"stdout","text":"🧠 Réponse générée: 10–12 times per minute\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# approche 2","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom sentence_transformers import SentenceTransformer, util\nimport spacy\n\n# 🔹 Charger les modèles\nqa_model_name = \"google/flan-t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(qa_model_name)\nqa_model = T5ForConditionalGeneration.from_pretrained(qa_model_name)\n\nsbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\nnlp = spacy.load(\"en_core_web_sm\")\n\n# 🔹 Encoder les documents une seule fois\ndoc_embeddings = sbert_model.encode(docs, convert_to_tensor=True)\n\n# 🔍 Récupération des documents pertinents avec score\ndef retrieve_relevant_docs(question, k=3):\n    question_embedding = sbert_model.encode(question, convert_to_tensor=True)\n    cosine_scores = util.cos_sim(question_embedding, doc_embeddings)[0]\n    top_k = torch.topk(cosine_scores, k=k)\n\n    # Renvoyer les documents + leurs scores\n    return [(docs[i], float(cosine_scores[i])) for i in top_k.indices]\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T19:39:20.669643Z","iopub.execute_input":"2025-05-01T19:39:20.670053Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e057ddecbefb408f86834e071c1c87de"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# ❓ Question exemple\nquestion = question=\" how applicate Mouth-To-Nose Rescue Breathing?\"\n\n\n# 🔍 Récupérer les documents pertinents avec scores\nrelevant_docs = retrieve_relevant_docs(question)\n\nprint(\"\\n🔹 Top documents with similarity scores:\")\nfor doc, score in relevant_docs:\n    print(f\"- 📈 Score de similarité : {score:.4f} | Document: {doc}\")\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"########################################  utilisation   ################################","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom sentence_transformers import SentenceTransformer, util\nimport spacy\n\n# 🔹 Charger les modèles\nqa_model_name = \"google/flan-t5-base\"\ntokenizer     = T5Tokenizer.from_pretrained(qa_model_name)\nqa_model      = T5ForConditionalGeneration.from_pretrained(qa_model_name)\n\nsbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\nnlp         = spacy.load(\"en_core_web_sm\")\n\n# 🔹 Préparer tes docs (inchangé)\ndoc_embeddings = sbert_model.encode(docs, convert_to_tensor=True)\n\ndef retrieve_relevant_docs(question, k=3):\n    q_emb         = sbert_model.encode(question, convert_to_tensor=True)\n    cosine_scores = util.cos_sim(q_emb, doc_embeddings)[0]\n    top_k         = torch.topk(cosine_scores, k=k)\n    return [docs[i] for i in top_k.indices]\n\ndef extract_key_sentences(context, question, max_sentences=3):\n    doc               = nlp(context)\n    keywords          = [t.text.lower() for t in nlp(question) if not t.is_stop]\n    relevant_sentences= []\n    for sent in doc.sents:\n        if any(kw in sent.text.lower() for kw in keywords):\n            relevant_sentences.append(sent.text)\n    return \" \".join(relevant_sentences[:max_sentences])\n\n# ➊ Extraction du passage de réponse\ndef extract_answer_span(question, context):\n    prompt = f\"\"\"\nYou are an information extraction assistant.\nExtract only the sentence(s) from the context that answer the question.\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nAnswer (extract):\n\"\"\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n    out    = qa_model.generate(**inputs, max_length=100, num_beams=5, early_stopping=True)\n    return tokenizer.decode(out[0], skip_special_tokens=True)\n\n# ➋ Paraphrase dans un style friendly\ndef paraphrase_text(text):\n    prompt = f\"\"\"\nParaphrase the following text and details in your own words, using a warm conversational tone,\nand end by inviting the user to ask a follow-up question .\n\nText to paraphrase:\n\\\"\\\"\\\"{text}\\\"\\\"\\\"\n\nParaphrased answer:\n\"\"\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n    out    = qa_model.generate(\n        **inputs,\n        min_length=20,\n        max_length=300,\n        num_beams=8,\n        length_penalty=1.2,\n        no_repeat_ngram_size=2,\n        early_stopping=True\n    )\n    return tokenizer.decode(out[0], skip_special_tokens=True)\n\n# ➌ Pipeline final\ndef chat_response(question, k_docs=3):\n    # Récupérer et filtrer le contexte\n    docs           = retrieve_relevant_docs(question, k=k_docs)\n    ctx_raw        = \" \".join(docs)\n    refined_ctx    = extract_key_sentences(ctx_raw, question)\n    # Extraction puis paraphrase\n    span           = extract_answer_span(question, refined_ctx)\n    answer         = paraphrase_text(span)\n    return answer\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question = \"Post-concussion syndrome is more common in women or men  ?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)\n    # print(\"Similarity Score (with question):\", response[\"scores\"][\"similarity_with_question\"])\n    # print(\"Similarity Score (with context):\", response[\"scores\"][\"similarity_with_context\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\" Low blood pressure does necessarily mean that the patient is in shock if not why ?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)\n  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\" what is The first step in dealing with an eye injury?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\" what is the  most the most common cause of  shock ?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\" what are the types of shock ?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"what are the domages cause by head inguries?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"what is first aid\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"what is pain\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"how applicate Mouth-To-Nose Rescue Breathing?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"How should abdominal thrusts be performed on a conscious person??\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"What are the two key questions to ask when managing a bleeding patient??\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# — Exemple d’utilisation —\nif __name__ == \"__main__\":\n    question =\"what are Signs And Symptoms of Shock?\"\n    response = chat_response(question)\n    print(\"💬 Bot :\", response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(doc_embeddings, \"doc_embeddings.pt\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# doc_embeddings = torch.load(\"doc_embeddings.pt\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# streamlit ","metadata":{}},{"cell_type":"code","source":"# import streamlit as st\n# import torch\n# import json\n# from sentence_transformers import SentenceTransformer, util\n# from transformers import T5Tokenizer, T5ForConditionalGeneration\n# import spacy\n\n# # --- Configuration GPU/CPU ---\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # 👇 Ceci doit être AVANT tout autre st.*\n# st.set_page_config(page_title=\"ChatMed Bot (CUDA)\", layout=\"wide\")\n\n# # 🔒 Caching des modèles et ressources lourdes\n# @st.cache_resource\n# def load_models():\n#     qa_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\").to(device)\n#     tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n#     sbert = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n#     nlp = spacy.load(\"en_core_web_sm\")\n#     return qa_model, tokenizer, sbert, nlp\n\n# @st.cache_data\n# def load_structure(path=\"structure (1).json\"):\n#     with open(path, \"r\", encoding=\"utf-8\") as f:\n#         return json.load(f)\n\n# @st.cache_data\n# def load_doc_embeddings(path=\"doc_embeddings.pt\"):\n#     return torch.load(path, map_location=device)\n\n# # ⏬ Chargement des modèles et données\n# qa_model, tokenizer, sbert_model, nlp = load_models()\n# structure = load_structure()\n# doc_embeddings = load_doc_embeddings()\n\n# # 🔄 Reconstruction des docs (plat)\n# docs = [f\"{section['title']}. {section['body']}\" \n#         for chapter in structure \n#         for section in chapter['sections']]\n\n# # 🔍 Récupération des docs pertinents\n# def retrieve_relevant_docs(question, k=3):\n#     question_embedding = sbert_model.encode(\n#         question, convert_to_tensor=True, device=device\n#     )\n#     cosine_scores = util.cos_sim(question_embedding, doc_embeddings)[0]\n#     top_k = torch.topk(cosine_scores, k=k)\n#     return [docs[i] for i in top_k.indices], top_k.values.tolist()\n\n# # 🔬 Extraction des phrases clés\n# def extract_key_sentences(context, question, max_sentences=3):\n#     doc = nlp(context)\n#     question_keywords = [token.text.lower() for token in nlp(question) if not token.is_stop]\n#     relevant_sentences = []\n#     for sent in doc.sents:\n#         if any(keyword in sent.text.lower() for keyword in question_keywords):\n#             relevant_sentences.append(sent.text)\n#     return \" \".join(relevant_sentences[:max_sentences])\n\n# # 🧠 Génération de réponse\n# def generate_answer(question, context):\n#     prompt = f\"\"\"\n# Based on the following context, answer the question concisely and include details.\n\n# Context:\n# {context}\n\n# Question:\n# {question}\n\n# Answer:\"\"\"\n#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n#     output = qa_model.generate(\n#         **inputs,\n#         max_length=150,\n#         num_beams=5,\n#         early_stopping=True\n#     )\n#     answer = tokenizer.decode(output[0], skip_special_tokens=True)\n#     return answer\n\n# # 🎯 Interface Streamlit\n# st.title(\"🧠 Semantic QA - Medical Document Assistant \")\n# st.markdown(\"Posez une question sur un document médical structuré.\")\n\n# question = st.text_input(\"❓ Votre question\")\n# if st.button(\"Get Answer\") and question:\n#     with st.spinner(\"🔍 Recherche en cours...\"):\n#         relevant_docs, scores = retrieve_relevant_docs(question, k=3)\n#         context = extract_key_sentences(\" \".join(relevant_docs), question)\n#         answer = generate_answer(question, context)\n\n#     st.subheader(\"📚 Documents pertinents (Top 3)\")\n#     for i, (doc, score) in enumerate(zip(relevant_docs, scores), 1):\n#         st.markdown(f\"**Doc {i} - Similarité cosinus :** `{score:.4f}`\")\n#         st.markdown(f\"> {doc[:300]}...\")  # Affiche un extrait (300 caractères)\n\n#     st.subheader(\"✅ Réponse générée\")\n#     st.write(answer)\n\n# # Footer\n# st.markdown(\"---\")\n# st.markdown(f\"**Device utilisé:** {device}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# streamlit run app.py\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# project/\n# ├── app.py\n# ├── structure.json\n# ├── doc_embeddings.pt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}